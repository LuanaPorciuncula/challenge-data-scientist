# PROJETO - Monitoramento de modelos de machine learning

Desenvolvimento de uma API para avaliação de performance e aderência [../monitoring/app/](../monitoring/app)

## Avaliando a API no notebook

Antes de rodar as células no notebook, inicie o servidor rodando o arquivo `monitoring\app\main.py` no ambiente Python.

![](https://github.com/LuanaPorciuncula/challenge-data-scientist/blob/main/gifs/run_server.gif)

O notebook de avaliação da API se encontra em [../monitoring\model_monitor.ipynb](..\monitoring\model_monitor.ipynb)

## Respostas das perguntas acerca do projeto

1. *Se quisermos expandir o monitoramento para todos os modelos atualmente em produção, você acha que pode dar algum problema caso haja muitas requisições simultâneas ao mesmo endpoint da API? O que podemos fazer neste caso?*
 - 


2. *Que outro problema um modelo de machine learning pode enfrentar em produção, que você ache interessante monitorar?*
 - 